{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-13T13:12:28.863764Z",
     "iopub.status.busy": "2022-08-13T13:12:28.862868Z",
     "iopub.status.idle": "2022-08-13T13:12:34.802514Z",
     "shell.execute_reply": "2022-08-13T13:12:34.801116Z",
     "shell.execute_reply.started": "2022-08-13T13:12:28.863664Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'learntools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Environment Set-Up for feedback system.\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binder\n\u001b[0;32m      8\u001b[0m binder\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml_explainability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mex3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'learntools'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Environment Set-Up for feedback system.\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.ml_explainability.ex3 import *\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "# Data manipulation code below here\n",
    "data = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv', nrows=50000)\n",
    "\n",
    "# Remove data with extreme outlier coordinates or negative fares\n",
    "data = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +\n",
    "                  'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +\n",
    "                  'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +\n",
    "                  'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +\n",
    "                  'fare_amount > 0'\n",
    "                  )\n",
    "\n",
    "y = data.fare_amount\n",
    "\n",
    "base_features = ['pickup_longitude',\n",
    "                 'pickup_latitude',\n",
    "                 'dropoff_longitude',\n",
    "                 'dropoff_latitude']\n",
    "\n",
    "X = data[base_features]\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "first_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)\n",
    "print(\"Data sample:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-13T13:12:34.805231Z",
     "iopub.status.busy": "2022-08-13T13:12:34.804765Z",
     "iopub.status.idle": "2022-08-13T13:12:34.854593Z",
     "shell.execute_reply": "2022-08-13T13:12:34.853208Z",
     "shell.execute_reply.started": "2022-08-13T13:12:34.805198Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Here is the code to plot the partial dependence plot for pickup_longitude.  Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-13T13:12:45.510475Z",
     "iopub.status.busy": "2022-08-13T13:12:45.510053Z",
     "iopub.status.idle": "2022-08-13T13:12:46.638328Z",
     "shell.execute_reply": "2022-08-13T13:12:46.637141Z",
     "shell.execute_reply.started": "2022-08-13T13:12:45.510438Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-13T13:13:28.218733Z",
     "iopub.status.busy": "2022-08-13T13:13:28.218258Z",
     "iopub.status.idle": "2022-08-13T13:13:31.762778Z",
     "shell.execute_reply": "2022-08-13T13:13:31.761631Z",
     "shell.execute_reply.started": "2022-08-13T13:13:28.218700Z"
    }
   },
   "outputs": [],
   "source": [
    "for feat_name in base_features:\n",
    "    pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X,\n",
    "                               model_features=base_features, feature=feat_name)\n",
    "    pdp.pdp_plot(pdp_dist, feat_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-13T13:14:32.046649Z",
     "iopub.status.busy": "2022-08-13T13:14:32.046197Z",
     "iopub.status.idle": "2022-08-13T13:14:38.110667Z",
     "shell.execute_reply": "2022-08-13T13:14:38.109650Z",
     "shell.execute_reply.started": "2022-08-13T13:14:32.046610Z"
    }
   },
   "outputs": [],
   "source": [
    "fnames = ['pickup_longitude', 'dropoff_longitude']\n",
    "longitudes_partial_plot  =  pdp.pdp_interact(model=first_model, dataset=val_X,\n",
    "                                            model_features=base_features, features=fnames)\n",
    "pdp.pdp_interact_plot(pdp_interact_out=longitudes_partial_plot,\n",
    "                      feature_names=fnames, plot_type='contour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-13T13:16:28.693908Z",
     "iopub.status.busy": "2022-08-13T13:16:28.693451Z",
     "iopub.status.idle": "2022-08-13T13:16:35.651269Z",
     "shell.execute_reply": "2022-08-13T13:16:35.649975Z",
     "shell.execute_reply.started": "2022-08-13T13:16:28.693861Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is the PDP for pickup_longitude without the absolute difference features. Included here to help compare it to the new PDP you create\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist_original = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist_original, feat_name)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# create new features\n",
    "data['abs_lon_change'] = abs(data.dropoff_longitude - data.pickup_longitude)\n",
    "data['abs_lat_change'] = abs(data.dropoff_latitude - data.pickup_latitude)\n",
    "\n",
    "features_2  = ['pickup_longitude',\n",
    "               'pickup_latitude',\n",
    "               'dropoff_longitude',\n",
    "               'dropoff_latitude',\n",
    "               'abs_lat_change',\n",
    "               'abs_lon_change']\n",
    "\n",
    "X = data[features_2]\n",
    "new_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\n",
    "second_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n",
    "\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist = pdp.pdp_isolate(model=second_model, dataset=new_val_X, model_features=features_2, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n",
    "\n",
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "\n",
    "n_samples = 20000\n",
    "\n",
    "# Create array holding predictive feature\n",
    "X1 = 4 * rand(n_samples) - 2\n",
    "X2 = 4 * rand(n_samples) - 2\n",
    "# Create y. you should have X1 and X2 in the expression for y\n",
    "y = np.ones(n_samples)\n",
    "\n",
    "# create dataframe because pdp_isolate expects a dataFrame as an argument\n",
    "my_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "predictors_df = my_df.drop(['y'], axis=1)\n",
    "\n",
    "my_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n",
    "\n",
    "pdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n",
    "\n",
    "# visualize your results\n",
    "pdp.pdp_plot(pdp_dist, 'X1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "n_samples = 20000\n",
    "\n",
    "# Create array holding predictive feature\n",
    "X1 = 4 * rand(n_samples) - 2\n",
    "X2 = 4 * rand(n_samples) - 2\n",
    "# Create y. you should have X in the expression for y\n",
    "y = X1 * X2\n",
    "\n",
    "\n",
    "# create dataframe because pdp_isolate expects a dataFrame as an argument\n",
    "my_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "predictors_df = my_df.drop(['y'], axis=1)\n",
    "\n",
    "my_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n",
    "\n",
    "\n",
    "pdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n",
    "pdp.pdp_plot(pdp_dist, 'X1')\n",
    "plt.show()\n",
    "\n",
    "perm = PermutationImportance(my_model).fit(predictors_df, my_df.y)\n",
    "\n",
    "# Check your answer\n",
    "q_7.check()\n",
    "\n",
    "# show the weights for the permutation importance you just calculated\n",
    "eli5.show_weights(perm, feature_names = ['X1', 'X2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
